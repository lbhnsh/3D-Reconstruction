---
title: C2_W1
created: '2023-09-12T09:19:08.560Z'
modified: '2023-09-13T10:02:44.358Z'
---

# C2_W1

__Training, Developing and Testing sets__

Data is slices into train, dev and test subsets according to 98:1:1, 99:0.5:0.5, 99.5:0.4:0.1 or any other similar ratio.

In case of Deep learning model for classifying whether image is of cat or not;
Training set contains cat pictures from webpages whereas dev and test sets contains cat pictures from users using your app.

___
__Bias and variance__

|Train set error|1%|15%|15%|0.5%|
|---------------|--|---|---|----|
|Dev set error|11%|16%|30%|1%|
|  |high variance|high bias|high variance and high bias|low variance and low bias|

__Bias__ is the systematic and repeatable portion of the prediction that results in a consistent yet less desirable result. A model leaning more towards bias will result in underfitting, i.e. predictions that are too general to be useful.
__Variance__ is the seemingly random portion of the prediction that represents the spread of results around an expected value. A model leaning more towards variance will result in overfitting, i.e. predictions that are different without a justifiable cause.

Relationship between bias and variance
![b&v](https://miro.medium.com/v2/resize:fit:828/format:webp/1*VwfPWNCCbtuer0OldD-nuw.png)

If bias is high, we go for a bigger networkork or expand number of nodes of our network. If variance is high, we increase quantity of input data and applu regularization techniques.
___
__Regularization__

Logistic Regression

![reg in LR](https://miro.medium.com/v2/resize:fit:828/format:webp/1*7S6lwTgY129EFhBIKQVYUg.png)

When too many input features are under consideration, we often overfit the data. Overfitting is a modeling error in a function that is closely fit to a data set. It captures the noise in the data set, and may not fit new incoming data.
To overcome this issue, we mainly have two choices: 1) remove less useful features, 2) use regularization.

J(W,b) = (1/m)*∑<sub>i=1</sub><sup>i=m</sup> L(y^<sup>(i)</sup>,y<sup>(i)</sup>) + (λ/2m)*||W||<sup>2</sup><sub>z</sub>

L2 regularization : ||W||<sup>2</sup><sub>z</sub> = ∑<sub>j=1</sub><sup>j=nx</sup> W<sub>j</sub><sup>2</sup> = W<sup>T</sup>W

L1 regularization : (λ/2m)*∑<sub>j=1</sub><sup>j=nx</sup> |W<sub>j</sub>| = (λ/2m)*||W||<sub>1</sub>

J(W<sup>[1]</sup>,b<sup>[1]</sup>,...,W<sup>[L]</sup>,<sup>[L]</sup>) = (1/m)*∑<sub>i=1</sub><sup>i=m</sup> L(y^<sup>(i)</sup>,y<sup>(i)</sup>) + (λ/2m)*||W<sup>[L]</sup>||<sup>2</sup>

Regularization is very useful in overcoming overfitting. It allows us to retain even slightly useful features and automatically reduces the coefficient of those features.

---
__Dropout regularization__

Basic intuition : Can't rely on one feature so have to spread out weights.

Dropout regularization is done by randomly removing some nodes from the network during training. The removed nodes do not participate in the parameter updating process.

![dropout](https://miro.medium.com/v2/resize:fit:828/format:webp/1*x2fNq-Y1BZtPRQc-Va_A5Q.png)


After applying dropout regularization to each layer, the original network becomes smaller. The training process is done using the smaller network.

By randomly removing nodes from the network, a smaller network is used for updating parameters. When the network becomes smaller, it provides less flexibility which results in reducing overfitting.

By randomly removing nodes from the network, the weights associated with those nodes will also be inactive (zero). So, other weights need to participate in the learning process. When this happens at each iteration, the weights are spread out much more and all weights are updated properly instead of updating some weights too much. The network's output does not depend on certain large weights. This can reduce overfitting in neural networks.

1. At each iteration, a different set of randomly selected nodes will be removed when applying dropout regularization.
2. Dropout regularization is only applied during training. The evaluation (testing) process is done using the original network.
3. In general, dropout regularization works better with larger neural networks.
4. Dropout regularization is applied per-layer basis. It is not used in the input and output layers.
5. We can apply dropout regularization with different ratevalues and plot the model performance against the number of epochs during the training.
6. When you apply activation as a layer, the dropout layer (if any) is always placed before the activation layer.

Example : for l = 3 , keep_prob = 0.8
d3 = np.random.randn(a3.shape[0],a3.shape[1]) < keep_prob

a3 = a3 * d3
a3 = a3 / keep_prob

___

__Normalizing inputs__

Normalizing training sets

Subtotal mean :

μ = (1/m) * ∑ <sub>i=1</sub><sup>i=m</sup> X<sup>(i)</sup>
X = X - μ

Normal variance :

σ<sup>2</sup> = (1/m)* ∑ <sub>i=1</sub><sup>i=m</sup> X<sup>(i)</sup> ** 2
x = x / σ<sup>2</sup>

We use μ and σ<sup>2</sup> to normalize test set

---

__Vanishing and Exploding gradients__
The problem of vanishing and exploding gradients stems from the initialization of the weights. Both of the above issues lead to improper and slower training of the network. As their names suggest, vanishing gradients occur when the weights vanish and end up being too small; whereas, in exploding gradients, the weights explode and become too big.
Example 
Let W be the weight matrix of all layers initialized close to the identity matrix I.
![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*_9nTV3QY0ojVmSkd63wbyg.png)

In forward propagation, output Z of a layer is defined by - 
Z = W<sup>T</sup>X + b

If we perform the above computation over L layers, then we can assume that the weight matrices W will be multiplied L times ignoring the bias.

if a particular value which is greater than 1, let say 1.5, the activation of the layers will increase exponentially, the gradients will be big, and gradient descent will take huge steps, and the network will take a long time to reach the minimum. This problem is known as exploding gradients.
Similarly, if a particular value less than 1, let say 0.9, the activation of the layers will decrease exponentially, the gradients will be too small, and gradient descent will take minuscule steps and taking a long time to reach the minimum. This problem is known as vanishing gradients.

To avoid the problem of exploding and vanishing gradients - 
1. The mean of the activations should be zero.
2. The variance of the activations should stay the same across every layer.

__Xavier Initialization__
Xavier initialization is used when the activation function of a specific layer is Tanh
```
# Let the dimesnion of weight matrix be(5,3)
# The variance is (1/neurons in previous layer)
# Randn ensure that the mean = 0
W = np.random.randn(5,3) * np.sqrt(1/3))
```
___

Derivative computation

g(θ) = f`(θ)

(f(θ+h) - f(θ))/h = g(θ)

___

__Gradient Checking : Debugging a Neural Network__
The method of gradient checking involves approximating the gradient using numerical approach. If it is close to calculated gradients, then backpropagation is implemented correctly!

![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*_NJ2_tDdA1kJX7V9BocE2g.png)

Vectorized Implementation

We take the weights and bias matrices and reshape them into a big vector θ. Similarly, all their respective derivatives will be placed into a vector d_theta.
for approximation of gradient
![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*RqqVCinHAdPAYUGhh3OaZw.png)

for checking gradient

![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*poPIZIlVLupYCP2VEiHRpg.png)




































